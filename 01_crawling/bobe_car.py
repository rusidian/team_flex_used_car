# -------------------------------------------------
# í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ / ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
# -------------------------------------------------
import random
from datetime import time
from pathlib import Path
from typing import Dict, Optional, Any, List

import pandas as pd
import requests
from bs4 import BeautifulSoup as bs


# í”„ë¡œì íŠ¸ ê³µí†µ ë°ì´í„° ì €ì¥ ê²½ë¡œ
from crawling.common.paths import DATA_DIR

# í”„ë¡œì íŠ¸ ì •ê·œì‹
from crawling.parsers.regex_patterns import RE_MODEL_CODE, RE_MAKER_CODE, RE_TO_INT, RE_PAGECLICK


class BobeCar:
    """
    ë³´ë°°ë“œë¦¼ ì¤‘ê³ ì°¨ ì‚¬ì´íŠ¸ì—ì„œ
    ì œì¡°ì‚¬/ëª¨ë¸/ì„¸ëŒ€ëª¨ë¸ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê¸° ìœ„í•œ í´ë˜ìŠ¤
    """

    def __init__(self):
        # ì œì¡°ì‚¬/ëª¨ë¸ ëª©ë¡ í˜ì´ì§€ì˜ ê³µí†µ ë² ì´ìŠ¤ URL
        self.__BASE_URL = "https://www.bobaedream.co.kr/mycar/mycar_list.php?gubun="

    def fetch_soup(self, url: str) -> BeautifulSoup:
        """
        ì£¼ì–´ì§„ URLì— HTTP ìš”ì²­ì„ ë³´ë‚´ HTMLì„ ê°€ì ¸ì˜¨ ë’¤,
        BeautifulSoup ê°ì²´ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.

        - ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜
        - HTTP ì˜¤ë¥˜(4xx, 5xx)
        ë°œìƒ ì‹œ ì˜ˆì™¸ë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤.

        :param url: ìš”ì²­í•  í˜ì´ì§€ URL
        :return: BeautifulSoup ê°ì²´
        """

        try:
            # í˜ì´ì§€ ìš”ì²­ (ì‘ë‹µì´ ì—†ìœ¼ë©´ 10ì´ˆ í›„ íƒ€ì„ì•„ì›ƒ)
            response = requests.get(url, timeout=10)

            # HTTP ìƒíƒœ ì½”ë“œê°€ 4xx / 5xx ì¸ ê²½ìš° ì˜ˆì™¸ ë°œìƒ
            response.raise_for_status()

            # HTML â†’ BeautifulSoup ë³€í™˜
            html = response.text
            soup = BeautifulSoup(html, "html.parser")
            return soup

        except requests.exceptions.RequestException as e:
            # ìš”ì²­/ë„¤íŠ¸ì›Œí¬/HTTP ì˜¤ë¥˜ ë¡œê·¸ ì¶œë ¥ í›„ ì˜ˆì™¸ ì¬ì „íŒŒ
            print(f"[ERROR] Failed to fetch URL: {url} | {e}")
            raise

    def standardize_dataframe(
            self,
            data: dict,
            data_key: str,
            index_col: str | None = None
    ) -> pd.DataFrame:
        """
        dict ì•ˆì— ë“¤ì–´ìˆëŠ” list[dict] ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        í•„ìš”í•˜ë©´ íŠ¹ì • ì»¬ëŸ¼ì„ indexë¡œ ì„¤ì •í•©ë‹ˆë‹¤.

        :param data: ì›ë³¸ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
                     ì˜ˆ) {"makers": [...], "models": [...]}
        :param data_key: DataFrameìœ¼ë¡œ ë³€í™˜í•  key
                         ì˜ˆ) "makers"
        :param index_col: DataFrame indexë¡œ ì‚¬ìš©í•  ì»¬ëŸ¼ëª… (ì„ íƒ)
        :return: í‘œì¤€í™”ëœ DataFrame
        """

        try:
            # ìš”ì²­í•œ keyê°€ dataì— ì—†ëŠ” ê²½ìš°
            if data_key not in data:
                raise KeyError(f"'{data_key}' not found in data")

            # list[dict] â†’ DataFrame ë³€í™˜
            df = pd.DataFrame(data[data_key])

            # ë°ì´í„°ê°€ ë¹„ì–´ ìˆëŠ” ê²½ìš°
            if df.empty:
                raise ValueError(f"Data for '{data_key}' is empty")

            # index ì„¤ì •ì´ í•„ìš”í•œ ê²½ìš°
            if index_col:
                if index_col not in df.columns:
                    raise ValueError(
                        f"index_col '{index_col}' not in columns: {list(df.columns)}"
                    )
                df = df.set_index(index_col)

            return df

        except Exception as e:
            # DataFrame ë³€í™˜ ë‹¨ê³„ì—ì„œ ë°œìƒí•œ ëª¨ë“  ì˜¤ë¥˜ ë¡œê·¸ ì¶œë ¥
            print(f"[ERROR] standardize_dataframe failed: {e}")
            raise

    def save_df_to_csv(
            self,
            df: pd.DataFrame,
            filename: str,
            dedup_keys: list[str],
            encoding: str = "utf-8",
    ) -> Path | None:
        """
        DataFrameì„ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

        - ê¸°ì¡´ CSV íŒŒì¼ì´ ìˆìœ¼ë©´:
          ê¸°ì¡´ ë°ì´í„° + ìƒˆ ë°ì´í„°ë¥¼ ë³‘í•©í•œ ë’¤,
          dedup_keys ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±° í›„ ì €ì¥í•©ë‹ˆë‹¤.
        - ê¸°ì¡´ íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.

        :param df: ì €ì¥í•  DataFrame
        :param filename: ì €ì¥í•  íŒŒì¼ëª… (í™•ì¥ì ì—†ìœ¼ë©´ .csv ìë™ ì¶”ê°€)
        :param dedup_keys: ì¤‘ë³µ ì œê±° ê¸°ì¤€ ì»¬ëŸ¼ ëª©ë¡
        :param encoding: CSV ì¸ì½”ë”© ë°©ì‹
        :return: ì €ì¥ëœ CSV íŒŒì¼ ê²½ë¡œ (Path)
        """

        # ì €ì¥í•  ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°
        if df is None or df.empty:
            print("[WARN] DataFrame is empty or None. Skip saving.")
            return None

        # íŒŒì¼ëª…ì— .csv í™•ì¥ìê°€ ì—†ìœ¼ë©´ ìë™ ì¶”ê°€
        if not filename.lower().endswith(".csv"):
            filename = f"{filename}.csv"

        # ìµœì¢… ì €ì¥ ê²½ë¡œ
        file_path = DATA_DIR / filename

        try:
            # ê¸°ì¡´ CSV íŒŒì¼ì´ ìˆëŠ” ê²½ìš°
            if file_path.exists():
                # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
                old_df = pd.read_csv(file_path, encoding=encoding)

                # ê¸°ì¡´ ë°ì´í„° + ì‹ ê·œ ë°ì´í„° ë³‘í•©
                # ğŸ”¹ ì‹ ê·œ df ìª½ dtype ë¨¼ì € ì •ë¦¬
                int_cols = [
                    "maker_code", "model_code", "generation_code",
                    "grade_code", "grade_volume",
                    "term_code", "term_volume"
                ]

                for c in int_cols:
                    if c in df.columns:
                        df[c] = pd.to_numeric(df[c], errors="coerce").astype("Int64")

                # ê·¸ ë‹¤ìŒ concat
                merged_df = pd.concat([old_df, df], ignore_index=True)

                # ì¤‘ë³µ ì œê±° ê¸°ì¤€ ì»¬ëŸ¼ ê²€ì¦
                missing = [k for k in dedup_keys if k not in merged_df.columns]
                if missing:
                    raise ValueError(f"dedup_keysì— ì—†ëŠ” ì»¬ëŸ¼ì´ í¬í•¨ë¨: {missing}")

                # ì¤‘ë³µ ì œê±°
                merged_df = merged_df.drop_duplicates(
                    subset=dedup_keys,
                    keep="first"
                )
            else:
                # ê¸°ì¡´ íŒŒì¼ì´ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                merged_df = df

            # CSV íŒŒì¼ ì €ì¥ (í•­ìƒ ë®ì–´ì“°ê¸°)
            merged_df.to_csv(file_path, index=False, encoding=encoding)

            print(f"[INFO] CSV updated: {file_path} (rows={len(merged_df)})")
            return file_path

        except Exception as e:
            # CSV ì €ì¥ ê³¼ì •ì—ì„œ ë°œìƒí•œ ì˜¤ë¥˜ ë¡œê·¸ ì¶œë ¥
            print(f"[ERROR] save_df_to_csv failed: {file_path} | {e}")
            raise

    def get_maker_category(self, origin: str) -> dict:
        """
        ì œì¡°ì‚¬ ëª©ë¡ì„ ìˆ˜ì§‘í•˜ê³ ,
        DataFrameìœ¼ë¡œ ë³€í™˜í•œ ë’¤ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

        ì œì¡°ì‚¬ í˜ì´ì§€ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        - maker_name  : ì œì¡°ì‚¬ ì´ë¦„
        - maker_code  : ì œì¡°ì‚¬ ì½”ë“œ
        - maker_volume: ì œì¡°ì‚¬ ë³´ìœ  ë§¤ë¬¼ ìˆ˜
        - origin      : ì°¨ëŸ‰ êµ¬ë¶„ ì½”ë“œ (K / I)

        :param origin: ì°¨ëŸ‰ êµ¬ë¶„ ì½”ë“œ
                       'K' = êµ­ì‚°ì°¨
                       'I' = ìˆ˜ì…ì°¨

        :return:
            {
                "ok": ì •ìƒ ì²˜ë¦¬ ì—¬ë¶€,
                "df": ìƒì„±ëœ ì œì¡°ì‚¬ DataFrame,
                "csv_path": ì €ì¥ëœ CSV íŒŒì¼ ê²½ë¡œ,
                "count": ì œì¡°ì‚¬ ê°œìˆ˜
            }
        """

        try:
            # ì œì¡°ì‚¬ í˜ì´ì§€ ìš”ì²­ ë° HTML íŒŒì‹±
            origin_url = self.__BASE_URL + origin
            soup = self.fetch_soup(origin_url)

            # ì œì¡°ì‚¬ ì˜ì—­ í™•ì¸
            car_category_tag = soup.select_one("div", class_="area-maker")
            if car_category_tag is None:
                raise ValueError("ì œì¡°ì‚¬ ì˜ì—­(area-maker)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            # ì œì¡°ì‚¬ ë²„íŠ¼ ëª©ë¡ ì¶”ì¶œ
            car_categories = car_category_tag.select('[onclick^="car_depth_lite"]')
            if not car_categories:
                raise ValueError("ì œì¡°ì‚¬ ë²„íŠ¼(car_depth_lite)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            makers: list[dict] = []

            # ì œì¡°ì‚¬ ì •ë³´ íŒŒì‹±
            for idx, car_category in enumerate(car_categories, start=1):

                match = RE_MAKER_CODE.search(car_category.get("onclick", ""))
                if not match:
                    raise ValueError(f"[{idx}] ì œì¡°ì‚¬ ì½”ë“œ íŒŒì‹± ì‹¤íŒ¨")
                maker_code = int(match.group(1))

                name_tag = car_category.select_one("span.t1")
                if name_tag is None:
                    raise ValueError(f"[{idx}] ì œì¡°ì‚¬ ì´ë¦„(span.t1) ì—†ìŒ")
                maker_name = name_tag.get_text(strip=True)

                volume_tag = car_category.select_one("span.t2")
                if volume_tag is None:
                    raise ValueError(f"[{idx}] ì œì¡°ì‚¬ ë§¤ë¬¼ ìˆ˜(span.t2) ì—†ìŒ")
                maker_volume = int(volume_tag.get_text(strip=True))

                makers.append({
                    "maker_name": maker_name,
                    "maker_code": maker_code,
                    "maker_volume": maker_volume,
                    "origin": origin,
                })

            # DataFrame ë³€í™˜ (index = maker_name)
            df = self.standardize_dataframe(
                data={"makers": makers},
                data_key="makers",
                index_col="maker_name",
            )

            # CSV ì €ì¥ (ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•© í›„ ì¤‘ë³µ ì œê±°)
            csv_path = self.save_df_to_csv(
                df=df.reset_index(),
                filename="makers",
                dedup_keys=["maker_code", "origin"],
            )

            return {
                "ok": True,
                "df": df,
                "csv_path": csv_path,
                "count": len(df),
            }

        except Exception as e:
            print(f"[ERROR] get_maker_category failed (origin={origin}): {e}")
            raise

    def get_maker_models(self, origin: str, maker_code: int) -> dict:
        """
        ì œì¡°ì‚¬ì—ì„œ íŒë§¤ë¥¼ ëª¨ë¸ì˜ ì •ë³´ ìˆ˜ì§‘í•˜ê³ ,
        DataFrameìœ¼ë¡œ ë³€í™˜í•œ ë’¤ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

        ì œì¡°ì‚¬ í˜ì´ì§€ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        - maker_code  : ì œì¡°ì‚¬ ì½”ë“œ
        - origin      : ì°¨ëŸ‰ êµ¬ë¶„ ì½”ë“œ (K / I)
        - model_name  : ì°¨ëŸ‰ ëª¨ë¸ ì´ë¦„
        - model_code  : ì°¨ëŸ‰ ëª¨ë¸ ì½”ë“œ
        - model_volume: ì°¨ëŸ‰ ëª¨ë¸ ë“±ë¡ ëŒ€ìˆ˜

        :param origin: ì°¨ëŸ‰ êµ¬ë¶„ ì½”ë“œ
                       'K' = êµ­ì‚°ì°¨
                       'I' = ìˆ˜ì…ì°¨
        :param maker_code: ì œì¡°ì‚¬ ì½”ë“œ

        :return:
            {
                "ok": ì •ìƒ ì²˜ë¦¬ ì—¬ë¶€,
                "df": ìƒì„±ëœ ì°¨ëŸ‰ ëª¨ë¸ ì •ë³´ DataFrame,
                "csv_path": ì €ì¥ëœ CSV íŒŒì¼ ê²½ë¡œ,
                "count": ì°¨ëŸ‰ ëª¨ë¸ ê°œìˆ˜
            }
        """
        try:
            # ì œì¡°ì‚¬ ì°¨ëŸ‰ í˜ì´ì§€ ìš”ì²­ ë° HTML íŒŒì‹±
            maker_url = f'{self.__BASE_URL}{origin}&maker_no={maker_code}'
            soup = self.fetch_soup(maker_url)

            # ì°¨ëŸ‰ ëª¨ë¸ ì˜ì—­ í™•ì¸
            model_category_tag = soup.select_one("div", class_="area-model")
            if model_category_tag is None:
                raise ValueError("ì°¨ëŸ‰ ëª¨ë¸ ì˜ì—­(area-model)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            # ì°¨ëŸ‰ ëª¨ë¸ ë²„íŠ¼ ëª©ë¡ ì¶”ì¶œ
            model_categories = model_category_tag.select('button')
            if not model_categories:
                raise ValueError("ì°¨ëŸ‰ ëª¨ë¸ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            models: list[dict] = []

            # ì°¨ëŸ‰ ëª¨ë¸ ì •ë³´ íŒŒì‹±
            for idx, model_category in enumerate(model_categories, start=1):

                match = RE_MODEL_CODE.search((model_category.get("onclick", "")))
                if not match:
                    raise ValueError(f"[{idx}] ì°¨ëŸ‰ ëª¨ë¸ ì½”ë“œ íŒŒì‹± ì‹¤íŒ¨")
                model_code = int(match.group(1))

                name_tag = model_category.select_one("span.t1")
                if name_tag is None:
                    raise ValueError(f"[{idx}] ì°¨ëŸ‰ ëª¨ë¸ ì´ë¦„(span.t1) ì—†ìŒ")
                model_name = name_tag.get_text(strip=True)

                volume_tag = model_category.select_one("span.t2")
                if volume_tag is None:
                    raise ValueError(f"[{idx}] ì°¨ëŸ‰ ëª¨ë¸ ë§¤ë¬¼ ìˆ˜(span.t2) ì—†ìŒ")
                model_volume = int(volume_tag.get_text(strip=True))

                models.append({
                    "model_name": model_name,
                    "model_code": model_code,
                    "model_volume": model_volume,
                    "maker_code": maker_code,
                    "origin": origin,
                })

            # DataFrame ë³€í™˜ (index = model_name)
            df = self.standardize_dataframe(
                data={"models": models},
                data_key="models",
                index_col="model_name",
            )

            # CSV ì €ì¥ (ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•© í›„ ì¤‘ë³µ ì œê±°)
            csv_path = self.save_df_to_csv(
                df=df.reset_index(),
                filename="models",
                dedup_keys=["model_code", "maker_code", "origin"],
            )

            return {
                "ok": True,
                "df": df,
                "csv_path": csv_path,
                "count": len(df),
            }

        except Exception as e:
            print(f"[ERROR] get_maker_model failed (origin={origin},maker={maker_code}): {e}")
            raise

    def get_model_generation(
            self,
            origin: str,
            maker_code: int,
            model_code: int
    ) -> dict:
        """
    ì°¨ëŸ‰ ëª¨ë¸ì˜ ì„¸ëŒ€ ì •ë³´ ìˆ˜ì§‘í•˜ê³ ,
    DataFrameìœ¼ë¡œ ë³€í™˜í•œ ë’¤ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    ì œì¡°ì‚¬ í˜ì´ì§€ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    - maker_code  : ì œì¡°ì‚¬ ì½”ë“œ
    - origin      : ì°¨ëŸ‰ êµ¬ë¶„ ì½”ë“œ (K / I)
    - model_code  : ì°¨ëŸ‰ ëª¨ë¸ ì½”ë“œ
    - generation_name : ì°¨ëŸ‰ ëª¨ë¸ ì„¸ëŒ€ ì´ë¦„
    - generation_code : ì°¨ëŸ‰ ëª¨ë¸ ì„¸ëŒ€ ì½”ë“œ
    - generation_volume : ë“±ë¡ëœ ì°¨ëŸ‰ ëª¨ë¸ ì„¸ëŒ€ ëŒ€ìˆ˜

    :param origin: ì°¨ëŸ‰ êµ¬ë¶„ ì½”ë“œ
                   'K' = êµ­ì‚°ì°¨
                   'I' = ìˆ˜ì…ì°¨
    :param maker_code: ì œì¡°ì‚¬ ì½”ë“œ
    :param model_code: ì°¨ëŸ‰ ëª¨ë¸ ì½”ë“œ

    :return:
        {
            "ok": ì •ìƒ ì²˜ë¦¬ ì—¬ë¶€,
            "df": ìƒì„±ëœ ì°¨ëŸ‰ ëª¨ë¸ ì •ë³´ DataFrame,
            "csv_path": ì €ì¥ëœ CSV íŒŒì¼ ê²½ë¡œ,
            "count": ì°¨ëŸ‰ ëª¨ë¸ ì„¸ëŒ€ ê°œìˆ˜
        }
    """

        try:
            # ì°¨ëŸ‰ ì„¸ëŒ€ í˜ì´ì§€ ìš”ì²­ ë° HTML íŒŒì‹±
            model_url = f'{self.__BASE_URL}{origin}&maker_no={maker_code}&group_no={model_code}'
            soup = self.fetch_soup(model_url)

            # ì°¨ëŸ‰ ëª¨ë¸ ì„¸ëŒ€ ì˜ì—­ í™•ì¸
            generation_category_tag = soup.select_one("div.area-detail dl.group-list")
            if generation_category_tag is None:
                raise ValueError("ì°¨ëŸ‰ ëª¨ë¸ ì„¸ëŒ€ ì˜ì—­(area-detail)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            # ì°¨ëŸ‰ ëª¨ë¸ ì„¸ëŒ€ ëª©ë¡ ì¶”ì¶œ
            generation_dds = generation_category_tag.select("dd", recursive=False)
            generation_categories = [
                dd
                for dd in generation_dds
                if "display:none" not in (dd.get("style") or "").replace(" ", "").lower()
            ]
            if not generation_categories:
                raise ValueError("ì°¨ëŸ‰ ëª¨ë¸ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            generations: list[dict] = []

            # ì°¨ëŸ‰ ëª¨ë¸ ì„¸ë° ì •ë³´ íŒŒì‹±
            for idx, generation_category in enumerate(generation_categories, start=1):

                input_tag = generation_category.select_one('input[name="model_no[]"]')
                if not input_tag or not input_tag.has_attr("value"):
                    raise ValueError(f"[{idx}] ì°¨ëŸ‰ ëª¨ë¸ ì„¸ëŒ€ ì½”ë“œ íŒŒì‹± ì‹¤íŒ¨")
                generation_code = int(input_tag.get("value"))

                name_tag = generation_category.select_one("label")
                if name_tag is None:
                    raise ValueError(f"[{idx}] ì°¨ëŸ‰ ëª¨ë¸ ì„¸ëŒ€ ì´ë¦„(label) ì—†ìŒ")
                generation_name = name_tag.get_text(strip=True)

                volume_tag = generation_category.select_one("span.t2")
                if volume_tag is None:
                    raise ValueError(f"[{idx}] ì°¨ëŸ‰ ëª¨ë¸ ë§¤ë¬¼ ìˆ˜(span.t2) ì—†ìŒ")
                generation_volume = int(volume_tag.get_text(strip=True))

                generations.append({
                    "generation_name": generation_name,
                    "generation_code": generation_code,
                    "generation_volume": generation_volume,
                    "maker_code": maker_code,
                    "model_code": model_code,
                    "origin": origin,
                })

            # DataFrame ë³€í™˜ (index = model_name)
            df = self.standardize_dataframe(
                data={"generations": generations},
                data_key="generations",
                index_col="generation_name",
            )

            # CSV ì €ì¥ (ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•© í›„ ì¤‘ë³µ ì œê±°)
            csv_path = self.save_df_to_csv(
                df=df.reset_index(),
                filename="generations",
                dedup_keys=["generation_code", "model_code", "maker_code", "origin"],
            )

            return {
                "ok": True,
                "df": df,
                "csv_path": csv_path,
                "count": len(df),
            }


        except Exception as e:
            print(
                f"[ERROR] get_maker_generation failed (origin={origin},maker={maker_code},model={model_code}): {e}")
            raise

    def get_generation_terms(
            self,
            origin: str,
            maker_code: int,
            model_code: int,
            generation_code: int
    ) -> dict:
        """
        ì°¨ëŸ‰ ëª¨ë¸ì˜ ì„¸ëŒ€ ë“±ê¸‰/íŠ¸ë¦¼ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³ ,
        DataFrameìœ¼ë¡œ ë³€í™˜í•œ ë’¤ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

        ìˆ˜ì§‘ ì •ë³´:
        - grade_code, grade_name, grade_volume
        - term_code, term_name, term_volume
        """

        try:
            grades_url = (
                f"{self.__BASE_URL}{origin}"
                f"&dt=true&maker_no={maker_code}"
                f"&group_no={model_code}"
                f"&model_no[]={generation_code}"
            )
            soup = self.fetch_soup(grades_url)

            # ì°¨ëŸ‰ ëª¨ë¸ ì„¸ëŒ€ ë“±ê¸‰ ì˜ì—­ í™•ì¸
            grade_category_tag = soup.select_one("div.area-grade dl.group-list")
            if grade_category_tag is None:
                raise ValueError("ì°¨ëŸ‰ ëª¨ë¸ ì„¸ëŒ€ ë“±ê¸‰ ì˜ì—­(area-grade)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            # âœ… ìµœìƒìœ„ ë“±ê¸‰ ddë§Œ ì¶”ì¶œ
            grade_categories = grade_category_tag.select("dd", recursive=False)
            if not grade_categories:
                print(
                    f"[WARN] grade dd empty: origin={origin}, maker={maker_code}, model={model_code}, generation={generation_code}")
                empty_df = pd.DataFrame([], columns=[
                    "origin", "maker_code", "model_code", "generation_code",
                    "grade_code", "grade_name", "grade_volume",
                    "term_code", "term_name", "term_volume"
                ])
                csv_path = self.save_df_to_csv(
                    df=empty_df,
                    filename="terms",
                    dedup_keys=["origin", "maker_code", "model_code", "generation_code", "grade_code", "term_code"],
                )
                return {"ok": True, "df": empty_df, "csv_path": csv_path, "count": 0}
            rows: list[dict] = []

            # ì°¨ëŸ‰ ëª¨ë¸ ì„¸ëŒ€ ë“±ê¸‰ ì •ë³´ íŒŒì‹±
            for idx, grade_category in enumerate(grade_categories, start=1):

                input_tag = grade_category.select_one("input[name='level_no[]']")
                if not input_tag or not input_tag.has_attr("value"):
                    raise ValueError(f"[{idx}] ì°¨ëŸ‰ ëª¨ë¸ ì„¸ëŒ€ ë“±ê¸‰ ì½”ë“œ íŒŒì‹± ì‹¤íŒ¨")
                grade_code = int(input_tag.get("value"))

                name_tag = grade_category.select_one("label")
                if name_tag is None:
                    raise ValueError(f"[{idx}] ì°¨ëŸ‰ ëª¨ë¸ ì„¸ëŒ€ ë“±ê¸‰ ì´ë¦„(label) ì—†ìŒ")
                grade_name = name_tag.get_text(strip=True)

                volume_tag = grade_category.select_one("span.t2")
                if volume_tag is None:
                    raise ValueError(f"[{idx}] ì°¨ëŸ‰ ëª¨ë¸ ì„¸ëŒ€ ë“±ê¸‰ ë“±ë¡ ëŒ€ìˆ˜(span.t2) ì—†ìŒ")
                grade_volume = int(volume_tag.get_text(strip=True).replace(",", ""))

                # âœ… volume == 0 â†’ íŠ¸ë¦¼ í™•ì¥ í˜¸ì¶œ ì•ˆ í•¨
                if grade_volume == 0:
                    rows.append({
                        "origin": origin,
                        "maker_code": maker_code,
                        "model_code": model_code,
                        "generation_code": generation_code,
                        "grade_code": grade_code,
                        "grade_name": grade_name,
                        "grade_volume": grade_volume,
                        "term_code": None,
                        "term_name": None,
                        "term_volume": None,
                    })
                    continue

                # âœ… ë“±ê¸‰ë³„ íŠ¸ë¦¼ ìˆ˜ì§‘
                term_list = self.get_term_by_grade(grades_url, grade_code)

                # íŠ¸ë¦¼ì´ ì—†ëŠ” ê²½ìš° â†’ ë“±ê¸‰ë§Œ ì €ì¥
                if not term_list:
                    rows.append({
                        "origin": origin,
                        "maker_code": maker_code,
                        "model_code": model_code,
                        "generation_code": generation_code,
                        "grade_code": grade_code,
                        "grade_name": grade_name,
                        "grade_volume": grade_volume,
                        "term_code": None,
                        "term_name": None,
                        "term_volume": None,
                    })
                    continue

                # íŠ¸ë¦¼ì´ ìˆìœ¼ë©´ íŠ¸ë¦¼ë³„ row ìƒì„±
                for t in term_list:
                    rows.append({
                        "origin": origin,
                        "maker_code": maker_code,
                        "model_code": model_code,
                        "generation_code": generation_code,
                        "grade_code": grade_code,
                        "grade_name": grade_name,
                        "grade_volume": grade_volume,
                        **t,
                    })

            df = pd.DataFrame(rows)

            csv_path = self.save_df_to_csv(
                df=df,
                filename="terms",
                dedup_keys=[
                    "origin",
                    "maker_code",
                    "model_code",
                    "generation_code",
                    "grade_code",
                    "term_code",
                ],
            )

            return {
                "ok": True,
                "df": df,
                "csv_path": csv_path,
                "count": len(df),
            }

        except Exception as e:
            print(
                f"[ERROR] get_generation_terms failed "
                f"(origin={origin}, maker={maker_code}, model={model_code}, generation={generation_code}): {e}"
            )
            raise

    def get_term_by_grade(self, base_url: str, level_no: int) -> list[dict]:
        """
        íŠ¹ì • ë“±ê¸‰(level_no)ì˜ íŠ¸ë¦¼(level2_no) ëª©ë¡ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        - level_no íŒŒë¼ë¯¸í„°ë¥¼ ë¶™ì—¬ ì¬ìš”ì²­ í›„, level2_no[]ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.
        """
        try:
            term_url = f"{base_url}&level_no[]={level_no}"
            soup = self.fetch_soup(term_url)

            group = soup.select_one("div.area-grade dl.group-list")
            if group is None:
                return []

            term_inputs = group.select("input[name='level2_no[]']")
            if not term_inputs:
                return []

            terms: list[dict] = []
            seen_term_codes: set[int] = set()

            for inp in term_inputs:
                if not inp.has_attr("value"):
                    continue

                term_code = int(inp["value"])
                if term_code in seen_term_codes:
                    continue
                seen_term_codes.add(term_code)

                dd = inp.find_parent("dd")
                if dd is None:
                    continue

                label = dd.select_one("label")
                term_name = label.get_text(strip=True) if label else None
                if term_name in ("", "-"):
                    term_name = None

                cnt_tag = dd.select_one("span.t2")
                cnt_text = (cnt_tag.get_text(strip=True) if cnt_tag else "").replace(",", "")
                m = RE_TO_INT.search(cnt_text)
                term_volume = int(m.group(1)) if m else 0

                terms.append({
                    "term_code": term_code,
                    "term_name": term_name,
                    "term_volume": term_volume,
                })

            return terms

        except Exception as e:
            print(f"[ERROR] get_term_by_grade failed (level_no={level_no}): {e}")
            raise